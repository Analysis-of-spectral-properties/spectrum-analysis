# Look what we've got here...
Гипотеза: Отрицательных собственных значений всегда строго больше количества положительных.

Если предположить, что количество объектов всегда больше, чем три (так как для 1 нет смысла строить эту матрицу, а для двух количество отрицательных совпадает с количеством положительных), и что пространство конечномерное, то рассмотрим некоторые метрики подробнее для получения интуиции о виде метрик (некоторых функций), для которых эта гипотеза выполнена.
$N$ -- количество объектов (точек), $M$ -- размерность пространства, $s_+$ -- количество положительных с. з., $s_-$ -- кол-во отрицательных с. з.
## Overall
Метрики можно разделить на несколько семейств, условно они делятся как:
- **Отличные**. Для них наша гипотеза выполняется, кроме того, у матрицы, построенной на такой метрике, будет только одно положительное собственное значение, все остальные либо отрицательные, либо нулевые. Причём эмпирически было проверено, что если $M \ge N$, то у такой матрицы не будет нулевых собственных значений, а отрицательных будет в точности $N - 1$ . Если $M < N$, то отрицательных собственных зачений будет $M + f(M)$, где $f: \N \to \N$ - функция, которая возвращает натуральное число в зависимости от размерности, например, если $M \in [1, 5000]$, то $f(M) = 1$ (возможно, $f \equiv 1$). Соответственно, все остальные собственные значения - нулевые. К таким метрикам относятся euclidean и seuclidean.
"+" —> "0", "-" —> "+" ($D^2 \to B$).
- **Хорошие**. Для этих метрик наша гипотеза выполняется, но мы не можем ничего утверждать, кроме нашей гипотезы. К таким метрика относятся расстояния Минковского (при $p \ge 2$) и Чебышева. Причём выполняется только если $ M > 3 $.

Таким образом гипотеза выполняется только на метрике Минковского при $ M, N > 3$, причём в зависимости от выбора p можно получить некоторые приятные свойства, например, единственное положительное собственное значение, как в евклидовой метрике.
- **Плохие**. Для данных метрик было установлено, что выполнение гипотезы зависит от отношения $\phi = \frac{N}{M}$, где $N$ - количество объектов, $M$ - размерность пространства, то есть чем больше $\phi$, тем больше вероятность, что гипотеза для матрицы не будет выполняться. Причём эмпирически было установлено, что для каждой метрики значения $\phi$, после которого гипотеза начинает нарушаться, своё. Зачастую не имеют нулевых собственных значений, а количество отрицательных + количество положительных = $N$. К таким метрика относятся: cityblock, braycurtis, canberra...
- **Средние**. Эти метрики всё еще плохие, то есть гипотеза о преобладании отрицательных собственных значений не выполняется, но эмпирически было проверено, к чему стремится количество отрицательных собственных значений. Оказалось, что при $N \to \infty $ количество отрицательных собственных значений либо стремится к M (cosine), либо к M - 1 (correlation), либо к M + 1 (sqeuclidean). Учитывая, что при большом $M$ (например, при 100 для количества объектов не больше 2000) количество отрицательных и положительных в сумме дают ровно $N$, то мы точно знаем и количество положительных.

## Euclidean
$$
d(x, y) = \sqrt{\sum_{i=1}^n(x_i - y_i)^2}
$$
Относится к отличным метрикам. То есть $s_+ = 1 $, $s_- = M + 1$ при $N > M$.

## Seuclidean
$$
d(x, y) = \sqrt{\sum_{i=1}^n\frac{(x_i - y_i)^2}{V_i}}, V - вектор \ дисперсии
$$
Относится к отличным метрикам. То есть $s_+ = 1 $, $s_- = M + 1$ при $N > M$.

## Chebyshev
$$
d(x,y) = max_{1 \le i \le n } |x_i - y_i|
$$
Относится к хорошим метрикам. Как и у Минковского, гипотеза выполняется с $N \ge 4$, причём $s_+ + s_i = N$ всегда. Кроме того, $s_+, s_i \to \infty $, но $s_-$ растёт быстрее при выполненом условии.

## Minkowski
$$
d(x, y) = (\sum_{i=1}^n |x_i - y_i|^p)^{1/p}
$$
При определенных условиях (в частности, при $ p \ge 2$) относится к хорошим метрикам. Иначе к плохим. 

## Sqeuclidean
$$
d(x, y) = \sum_{i=}^n |x_i - y_i|^2
$$
Относится к средним метрикам. $s_- = M + 1$, а при достаточно большом M верно, что $s_- + s_+ = N $.

## Correlation
$$
d(x, y) = 1 - \frac{(x - \hat x) \cdot (y - \hat y)} {||(x - \hat x)||_2\ ||(y - \hat y)||_2}, \hat x, \hat y - среднее \ по \ векторам
$$
Относится к средним метрикам. $s_- = M - 1$, а при достаточно большом M верно, что $s_- + s_+ = N $.

## Cosine
$$
d(x, y) = 1 - \frac{x \cdot y}{||x||_2\ ||y||_2}
$$
Относится к средним метрикам. $s_- = M$, а при достаточно большом M верно, что $s_- + s_+ = N $.

## Canberra
$$
d(x, y) = \sum _{i=1} ^{n} \frac{|x_i - y_i|} {|x_i| + |y_i|}
$$
Относится к плохим метрикам. То есть гипотеза выполняется только при определенном соотношении $\frac{N}{M}$, $\ s_-, s_+ \to \infty$, но $s_+$ растёт быстрее.

## Bray–Curtis
$$
d(x, y) = \frac{\sum _{i=1} ^n|x_i - y_i|} {\sum _{i=1} ^ n |x_i + y_i|}
$$
Относится к плохим метрикам. То есть гипотеза выполняется только при определенном соотношении $\frac{N}{M}$, $\ s_-, s_+ \to \infty$, но $s_+$ растёт быстрее.

## Cityblock
$$
d(x, y) = \sum _{i=1}^n |x_i - y_i|
$$
Относится к плохим метрикам. То есть гипотеза выполняется только при определенном соотношении $\frac{N}{M}$, $\ s_-, s_+ \to \infty$, но $s_+$ растёт быстрее.
